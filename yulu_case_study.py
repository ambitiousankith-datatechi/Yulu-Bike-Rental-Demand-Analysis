# -*- coding: utf-8 -*-
"""yulu case study.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1d9vnu_DejNX51V6ETDir9KV_3BaBcAsE
"""

import pandas as pd

csv_link='https://d2beiqkhq929f0.cloudfront.net/public_assets/assets/000/001/428/original/bike_sharing.csv?1642089089'
df=pd.read_csv(csv_link)
df.head()

#missing values
print('Missing values')
print(df.isnull().sum())

#duplicate rows
print('Duplicate rows')
print(df.duplicated().sum())

#validate data types
print('Data types')
print(df.dtypes)

"""I dont see any missing values, duplicates and any mismatch in data type the looks clean."""

#Box Plot for count and working days
import matplotlib.pyplot as plt
import seaborn as sns
plt.figure(figsize=(8, 6))
sns.boxplot(x='workingday',y='count', data=df)
plt.title('Bike Rentals Count vs. Working Day')
plt.xlabel('Working Day (0: Weekend/Holiday, 1: Working Day)')
plt.ylabel('Bike Rentals Count')
plt.show()

#Box plot count vs holiday
plt.figure(figsize=(8, 6))
sns.boxplot(x='holiday',y='count', data=df)
plt.title('Bike Rentals Count vs. Holiday')
plt.show()

"""Both charts show us that special days (weekends/holidays) tend to be less busy than regular working days. While working days have a higher typical rental count and a slightly tighter range of common rental numbers, holidays have a lower typical rental count and also a tighter range of common rental numbers than non-working days. Both types of days have some unusual times where rentals are extremely high (those dots above the boxes are called outliers), but generally, our busiest times are on working days that aren't holidays."""

from scipy import stats

# 2-sample t-test for 'workingday' vs 'count'
# Assuming 'workingday' is a binary variable (0 or 1)
group1 = df[df['workingday'] == 0]['count']
group2 = df[df['workingday'] == 1]['count']

ttest_result = stats.ttest_ind(group1, group2)
print(f"2-sample t-test for Working Day vs Count: {ttest_result}")

"""The p-value is approximately 0.226. Since this p-value (0.226) is greater than the common significance level of 0.05, we do not have enough statistical evidence to conclude that there is a significant difference in the mean bike rentals between working days and non-working days at the 0.05 significance level based on this t-test."""

# Bar plot Weather Vs Count
plt.figure(figsize=(8, 6))
sns.barplot(x='weather', y='count', data=df)
plt.title('Average Bike Rentals Count vs. Weather')
plt.xlabel('Weather')
plt.ylabel('Bike Rentals Count')
plt.xticks(ticks=[0, 1, 2, 3], labels=['Clear/Few clouds', 'Mist/Cloudy', 'Light Rain/Snow', 'Heavy Rain/Snow/Fog']) # Assuming weather codes 1, 2, 3, 4 based on typical datasets
plt.show()

count_of_heavyrain=df[df['weather']==4]['count'].sum()
count_of_lightrain=df[df['weather']==3]['count'].sum()
print(f'heavyrain count {count_of_heavyrain},light rain count {count_of_lightrain}')

"""When the weather is nice (Clear or Mist/Cloudy), we rent the most bikes, and the number of rentals is fairly predictable. When it's raining or snowing lightly, we rent fewer bikes on average, and the number of rentals can be more unpredictable.When it's heavy rain, snow, or fog, we rent even more bikes comapared to light rain, but the number of rentals seems a bit more consistent than in light rain/snow.because the data is very less for the heavy rain condition when compared to others.

"""

# ANOVA for 'weather' vs 'count'
# Create a list of 'count' values for each weather condition
weather_groups = [df['count'][df['weather'] == w] for w in df['weather'].unique()]

anova_result_weather = stats.f_oneway(*weather_groups)
print(f"ANOVA for Weather vs Count: {anova_result_weather}")

"""Since this p-value (5.48e-42) is much less than the common significance level of 0.05, we have strong statistical evidence to reject the null hypothesis. We can conclude that there is a statistically significant difference in the mean bike rentals across the different weather conditions.

This indicates that 'weather' is a significant variable in predicting bike demand based on this ANOVA test. The average number of bike rentals varies significantly depending on the weather.

This finding aligns with the bar plot we created earlier, which visually showed differences in average bike rentals across weather categories.
"""

#Bar plot for season and count
plt.figure(figsize=(8, 6))
sns.barplot(x='season', y='count', data=df)
plt.title('Average Bike Rentals Count vs. Season')
plt.xlabel('Season')
plt.ylabel('Bike Rentals Count')
plt.xticks(ticks=[0, 1, 2, 3], labels=['Spring', 'Summer', 'Fall', 'Winter'])
plt.show()

#Anova for 'season' and 'count'
#create a season group
season_groups = [df['count'][df['season'] == s] for s in df['season'].unique()]

anova_result_season = stats.f_oneway(*season_groups)
print(f"ANOVA for Season vs Count: {anova_result_season}")

"""Since this p-value (6.16e-149) is much, much less than the common significance level of 0.05, we have very strong statistical evidence to reject the null hypothesis. We can conclude that there is a statistically significant difference in the mean bike rentals across the different seasons.

This indicates that 'season' is a highly significant variable in predicting bike demand based on this ANOVA test. The average number of bike rentals varies significantly depending on the season.

This finding aligns with the bar plot we created earlier (cell W2Iq3ENGMGuy), which visually showed clear differences in average bike rentals across the seasons, with higher averages in summer and fall compared to spring and winter.

So far, based on the bivariate ANOVA tests, both 'weather' and 'season' appear to be statistically significant variables in predicting bike demand. The t-test for 'workingday' did not show a significant difference in means at the 0.05 level in this bivariate context.
"""

import matplotlib.pyplot as plt
import seaborn as sns

plt.figure(figsize=(8, 6))
sns.scatterplot(x='atemp', y='count', data=df)
plt.title('Bike Rentals Count vs. Atemp')
plt.xlabel('Estimated Temperature (atemp)')
plt.ylabel('Bike Rentals Count')
plt.show()

"""The scatter plot visually confirms a positive association between estimated temperature and bike rentals, but it also highlights that this relationship is not perfectly linear and that temperature is just one of many factors influencing demand, as evidenced by the significant scatter in the data points."""

import statsmodels.api as sm

# Define the independent variable (atemp) and the dependent variable (count)
X = df['atemp']
y = df['count']

# Add a constant to the independent variable for the intercept
X = sm.add_constant(X)

# Create and fit the OLS (Ordinary Least Squares) model
model = sm.OLS(y, X).fit()

# Print the summary of the regression results
print(model.summary())

"""From these results, we can interpret the following about the relationship between 'atemp' and 'count':

Significance: 'atemp' is a highly statistically significant variable in predicting the bike rental count based on this simple linear regression. The positive coefficient (8.3316) indicates that as the estimated temperature increases, the bike rental count tends to increase.
How well it describes demand (linearly): While statistically significant, 'atemp' alone only explains about 15.2% of the variation in bike rentals. This suggests that 'atemp' is a relevant factor, but it doesn't fully capture all the factors influencing bike demand. There are many other variables and complexities that contribute to the remaining 84.8% of the variation in 'count'.
In summary, 'atemp' has a statistically significant positive linear relationship with bike rentals, but it only explains a modest portion of the total variation in demand when considered by itself in a simple linear model.
"""

import matplotlib.pyplot as plt
import seaborn as sns

plt.figure(figsize=(8, 6))
sns.scatterplot(x='humidity', y='count', data=df)
plt.title('Bike Rentals Count vs. Humidity')
plt.xlabel('Humidity')
plt.ylabel('Bike Rentals Count')
plt.show()

"""The scatter plot suggests a weak or negligible linear relationship between humidity and bike rentals. The high degree of scatter indicates that humidity, on its own, does not strongly explain the variation in bike rental demand. This visual observation aligns with the expectation that while extreme humidity might deter riders, within a certain range, other factors likely play a more significant role."""

#define independent variable (humidity) and dependent variable (count)
X = df['humidity']
y = df['count']

#add a constant to the independent variable for the intercept
X = sm.add_constant(X)

#create and fit the OLS (Ordinary Least Squares) model
model = sm.OLS(y, X).fit()

#print the summary of the regression results
print(model.summary())

"""From these results, we can interpret the following about the linear relationship between 'humidity' and 'count':

**Significance**: 'humidity' is a statistically significant variable in linearly predicting the bike rental count based on this simple linear regression. The negative coefficient (-2.9873) indicates that as humidity increases, the bike rental count tends to decrease, though the magnitude of this decrease for each unit increase in humidity is relatively small.
**How well it describes demand (linearly):** While statistically significant, 'humidity' alone explains only about 10.1% of the variation in bike rentals. This confirms our visual observation from the scatter plot that humidity is not a strong individual linear predictor of bike demand. Other factors play a much larger role in the remaining 89.9% of the variation.
In summary, 'humidity' has a statistically significant negative linear relationship with bike rentals, but it explains a very small portion of the total variation in demand when considered by itself in a simple linear model. The statistical significance indicates the relationship is unlikely due to chance, but the low R-squared shows it's not a powerful standalone predictor of the amount of variation in rentals.
"""

#scatter plot for Windspeed vs count
import matplotlib.pyplot as plt
import seaborn as sns

plt.figure(figsize=(8, 6))
sns.scatterplot(x='windspeed', y='count', data=df)
plt.title('Bike Rentals Count vs. Humidity')
plt.xlabel('windspeed')
plt.ylabel('Bike Rentals Count')
plt.show()

"""In summary, the scatter plot for 'windspeed' vs 'count' suggests a weak or negligible linear relationship. While very high windspeeds might be associated with lower maximum rental counts, windspeed on its own does not appear to be a strong individual linear predictor of the total bike rental count based on this visual analysis."""

import statsmodels.api as sm

# Define the independent variable (windspeed) and the dependent variable (count)
X = df['windspeed']
y = df['count']

# Add a constant to the independent variable for the intercept
X = sm.add_constant(X)

# Create and fit the OLS (Ordinary Least Squares) model
model = sm.OLS(y, X).fit()

# Print the summary of the regression results
print(model.summary())

"""From these results, we can interpret the following about the linear relationship between 'windspeed' and 'count':

Significance: 'windspeed' is statistically significant in linearly predicting the bike rental count.
How well it describes demand (linearly): Despite being statistically significant, 'windspeed' alone explains a very small portion of the variation in bike rentals (only 1%). This reinforces our visual observation from the scatter plot that while there might be a detectable linear relationship, it's extremely weak, and windspeed by itself is not a strong individual linear predictor of the amount of variation in demand. The positive coefficient is also a bit unexpected and suggests that a simple linear model might not fully capture the complex relationship between windspeed and bike rentals (e.g., perhaps very low wind is ideal, moderate wind is okay, and very high wind reduces rentals).
In summary, 'windspeed' has a statistically significant linear relationship with bike rentals, but it explains a negligible portion of the total variation in demand when considered by itself in a simple linear model.
"""

from scipy.stats import chi2_contingency
import pandas as pd

# Create a contingency table of 'season' and 'weather'
contingency_table = pd.crosstab(df['season'], df['weather'])
print("Contingency Table (Season vs Weather):")
display(contingency_table)

# Perform the Chi-square test for independence
chi2_statistic, p_value, dof, expected = chi2_contingency(contingency_table)

print(f"\nChi-square Test Results:")
print(f"Chi-square Statistic: {chi2_statistic}")
print(f"P-value: {p_value}")
print(f"Degrees of Freedom: {dof}")
# print(f"Expected Frequencies:\n{expected}") # Uncomment to see expected frequencies

"""Since the p-value (1.55e-07) is much less than 0.05, we have strong statistical evidence to reject the null hypothesis of independence between 'season' and 'weather'.

This means that 'season' and 'weather' are statistically dependent. The distribution of weather conditions is significantly different across the different seasons.
"""

import pandas as pd
import statsmodels.api as sm
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, r2_score
import numpy as np # Import numpy for sqrt

# Select features (independent variables) and target (dependent variable)
# Based on our bivariate analysis, 'season', 'weather', and 'atemp' appear to be significant.
# We will also include 'workingday', 'humidity', and 'windspeed' to see their collective impact.
features = ['season', 'weather', 'atemp', 'workingday', 'humidity', 'windspeed']
target = 'count'

X = df[features]
y = df[target]

# Handle categorical variables by creating dummy variables
X = pd.get_dummies(X, columns=['season', 'weather', 'workingday'])

# Convert boolean columns created by get_dummies to integer type
for col in X.columns:
    if X[col].dtype == 'bool':
        X[col] = X[col].astype(int)


# Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Add a constant to the independent variables for the intercept
X_train = sm.add_constant(X_train)
X_test = sm.add_constant(X_test)

# Create and fit the OLS (Ordinary Least Squares) model
model = sm.OLS(y_train, X_train).fit()

# Print the summary of the regression results for the training data
print("Multiple Linear Regression Model Summary (Training Data):")
print(model.summary())

# Make predictions on the test data
y_pred = model.predict(X_test)

# Evaluate the model on the test data
mse = mean_squared_error(y_test, y_pred)
rmse = np.sqrt(mse) # Calculate RMSE by taking the square root of MSE
r2 = r2_score(y_test, y_pred)

print("\nModel Evaluation on Test Data:")
print(f"Mean Squared Error (MSE): {mse}")
print(f"Root Mean Squared Error (RMSE): {rmse}")
print(f"R-squared (Test Data): {r2}")

"""The R-squared value on the test data is approximately 0.284.

This means that this set of variables (season, weather, atemp, workingday, humidity, and windspeed) collectively explains about 28.4% of the variation in bike rental demand. While this is a significant improvement over any single variable alone, it also indicates that a substantial portion (about 71.6%) of the factors influencing bike rental demand are not captured by this model. This could be due to missing variables, non-linear relationships, interactions between variables, or other complexities in the data.

In conclusion, based on this multiple linear regression analysis, atemp, humidity, windspeed, and certain categories of season and weather are statistically significant predictors of bike rental demand. Together, these variables explain nearly 30% of the variability in demand, providing a better understanding than looking at variables in isolation, but also highlighting that there are other important factors influencing bike rentals.
"""







